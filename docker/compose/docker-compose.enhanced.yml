# Enhanced Docker Compose for LlamaAgent Production System
# Author: Nik Jois <nikjois@llamasearch.ai>
# Version: 2.0.0

version: '3.9'

services:
  # Primary LlamaAgent Application
  llamaagent-app:
    build:
      context: .
      dockerfile: Dockerfile.enhanced
      target: runtime
      args:
        BUILD_DATE: ${BUILD_DATE:-$(date -u +'%Y-%m-%dT%H:%M:%SZ')}
        VCS_REF: ${VCS_REF:-HEAD}
        VERSION: ${VERSION:-2.0.0}
    container_name: llamaagent-app
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started
    environment:
      # Database Configuration
      DATABASE_URL: postgresql://${POSTGRES_USER:-llamaagent}:${POSTGRES_PASSWORD:-secure_password}@postgres:5432/llamaagent
      REDIS_URL: redis://redis:6379/0
      QDRANT_URL: http://qdrant:6333

      # LLM Provider Configuration
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      TOGETHER_API_KEY: ${TOGETHER_API_KEY:-}
      COHERE_API_KEY: ${COHERE_API_KEY:-}
      HUGGINGFACE_API_KEY: ${HUGGINGFACE_API_KEY:-}

      # Application Configuration
      LLAMAAGENT_ENV: production
      LLAMAAGENT_LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LLAMAAGENT_WORKERS: ${WORKERS:-4}
      LLAMAAGENT_MAX_MEMORY: ${MAX_MEMORY:-2G}
      LLAMAAGENT_DEBUG: ${DEBUG:-false}

      # Security Configuration
      SECRET_KEY: ${SECRET_KEY:-change_me_in_production}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-change_me_in_production}
      ALLOWED_HOSTS: ${ALLOWED_HOSTS:-*}
      CORS_ORIGINS: ${CORS_ORIGINS:-*}

      # Monitoring Configuration
      PROMETHEUS_ENABLED: ${PROMETHEUS_ENABLED:-true}
      PROMETHEUS_PORT: ${PROMETHEUS_PORT:-8001}
      GRAFANA_ENABLED: ${GRAFANA_ENABLED:-true}
      JAEGER_ENABLED: ${JAEGER_ENABLED:-true}

      # Performance Configuration
      CACHE_ENABLED: ${CACHE_ENABLED:-true}
      CACHE_TTL: ${CACHE_TTL:-3600}
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED:-true}
      RATE_LIMIT_PER_MINUTE: ${RATE_LIMIT_PER_MINUTE:-100}

    volumes:
      - ./config:/app/config:ro
      - app_logs:/app/logs
      - app_data:/app/data
      - app_cache:/app/cache
      - app_uploads:/app/uploads
      - app_exports:/app/exports
      - app_backups:/app/backups
    ports:
      - "${APP_PORT:-8000}:8000"
      - "${METRICS_PORT:-8001}:8001"
      - "${ADMIN_PORT:-8002}:8002"
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "/usr/local/bin/healthcheck.sh"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '${CPU_LIMIT:-2.0}'
          memory: ${MEMORY_LIMIT:-4G}
        reservations:
          cpus: '${CPU_RESERVATION:-1.0}'
          memory: ${MEMORY_RESERVATION:-2G}
    labels:
      - "com.llamaagent.service=app"
      - "com.llamaagent.version=${VERSION:-2.0.0}"
      - "traefik.enable=true"
      - "traefik.http.routers.app.rule=Host(`${APP_DOMAIN:-llamaagent.local}`)"
      - "traefik.http.services.app.loadbalancer.server.port=8000"

  # Background Worker for Async Tasks
  llamaagent-worker:
    build:
      context: .
      dockerfile: Dockerfile.enhanced
      target: runtime
    container_name: llamaagent-worker
    restart: unless-stopped
    command: ["python", "-m", "src.llamaagent.worker.main"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-llamaagent}:${POSTGRES_PASSWORD:-secure_password}@postgres:5432/llamaagent
      REDIS_URL: redis://redis:6379/0
      LLAMAAGENT_ENV: production
      LLAMAAGENT_LOG_LEVEL: ${LOG_LEVEL:-INFO}
      WORKER_CONCURRENCY: ${WORKER_CONCURRENCY:-4}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
    volumes:
      - ./config:/app/config:ro
      - app_logs:/app/logs
      - app_data:/app/data
      - app_cache:/app/cache
    networks:
      - llamaagent-network
    labels:
      - "com.llamaagent.service=worker"

  # PostgreSQL Database with pgvector
  postgres:
    image: pgvector/pgvector:pg16
    container_name: llamaagent-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-llamaagent}
      POSTGRES_USER: ${POSTGRES_USER:-llamaagent}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secure_password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --locale=C"
      PGUSER: ${POSTGRES_USER:-llamaagent}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
      - ./scripts/init-extensions.sql:/docker-entrypoint-initdb.d/02-extensions.sql:ro
      - postgres_backups:/backups
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-llamaagent} -d ${POSTGRES_DB:-llamaagent}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: ${POSTGRES_MEMORY_LIMIT:-1G}
        reservations:
          memory: ${POSTGRES_MEMORY_RESERVATION:-512M}
    labels:
      - "com.llamaagent.service=database"

  # Redis for Caching and Session Management
  redis:
    image: redis:7-alpine
    container_name: llamaagent-redis
    restart: unless-stopped
    command: >
      redis-server
      --appendonly yes
      --maxmemory ${REDIS_MAX_MEMORY:-512mb}
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: ${REDIS_MEMORY_LIMIT:-1G}
        reservations:
          memory: ${REDIS_MEMORY_RESERVATION:-256M}
    labels:
      - "com.llamaagent.service=cache"

  # Qdrant Vector Database for Embeddings
  qdrant:
    image: qdrant/qdrant:latest
    container_name: llamaagent-qdrant
    restart: unless-stopped
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__LOG_LEVEL: ${QDRANT_LOG_LEVEL:-INFO}
      QDRANT__CLUSTER__ENABLED: ${QDRANT_CLUSTER_ENABLED:-false}
    volumes:
      - qdrant_data:/qdrant/storage
      - ./config/qdrant:/qdrant/config:ro
    ports:
      - "${QDRANT_HTTP_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: ${QDRANT_MEMORY_LIMIT:-2G}
        reservations:
          memory: ${QDRANT_MEMORY_RESERVATION:-512M}
    labels:
      - "com.llamaagent.service=vector-db"

  # Nginx Reverse Proxy with SSL and Load Balancing
  nginx:
    image: nginx:alpine
    container_name: llamaagent-nginx
    restart: unless-stopped
    ports:
      - "${HTTP_PORT:-80}:80"
      - "${HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_cache:/var/cache/nginx
      - nginx_logs:/var/log/nginx
    depends_on:
      - llamaagent-app
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.llamaagent.service=proxy"

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: llamaagent-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.llamaagent.service=monitoring"

  # Grafana Dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: llamaagent-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_INSTALL_PLUGINS: ${GRAFANA_PLUGINS:-grafana-piechart-panel,grafana-worldmap-panel}
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SMTP_ENABLED: ${GRAFANA_SMTP_ENABLED:-false}
      GF_ALERTING_ENABLED: ${GRAFANA_ALERTING_ENABLED:-true}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    depends_on:
      - prometheus
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.llamaagent.service=visualization"

  # Jaeger Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: llamaagent-jaeger
    restart: unless-stopped
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
      COLLECTOR_ZIPKIN_HOST_PORT: ":9411"
      SPAN_STORAGE_TYPE: ${JAEGER_STORAGE_TYPE:-memory}
      JAEGER_DISABLED: ${JAEGER_DISABLED:-false}
    ports:
      - "${JAEGER_UI_PORT:-16686}:16686"
      - "${JAEGER_COLLECTOR_PORT:-14268}:14268"
      - "${JAEGER_GRPC_PORT:-14250}:14250"
      - "${JAEGER_OTLP_HTTP_PORT:-14269}:14269"
    networks:
      - llamaagent-network
    volumes:
      - jaeger_data:/tmp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:16686/"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.llamaagent.service=tracing"

  # Elasticsearch for Log Aggregation
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: llamaagent-elasticsearch
    restart: unless-stopped
    environment:
      discovery.type: single-node
      ES_JAVA_OPTS: "-Xms${ELASTICSEARCH_HEAP_SIZE:-1g} -Xmx${ELASTICSEARCH_HEAP_SIZE:-1g}"
      xpack.security.enabled: "false"
      xpack.monitoring.collection.enabled: "true"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: ${ELASTICSEARCH_MEMORY_LIMIT:-2G}
        reservations:
          memory: ${ELASTICSEARCH_MEMORY_RESERVATION:-1G}
    labels:
      - "com.llamaagent.service=logging"

  # Logstash for Log Processing
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: llamaagent-logstash
    restart: unless-stopped
    volumes:
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./monitoring/logstash/config:/usr/share/logstash/config:ro
      - app_logs:/app/logs:ro
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - llamaagent-network
    environment:
      LS_JAVA_OPTS: "-Xms${LOGSTASH_HEAP_SIZE:-512m} -Xmx${LOGSTASH_HEAP_SIZE:-512m}"
    labels:
      - "com.llamaagent.service=log-processing"

  # Kibana for Log Visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: llamaagent-kibana
    restart: unless-stopped
    environment:
      ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
      ELASTICSEARCH_USERNAME: ${KIBANA_USERNAME:-kibana}
      ELASTICSEARCH_PASSWORD: ${KIBANA_PASSWORD:-kibana}
    ports:
      - "${KIBANA_PORT:-5601}:5601"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "com.llamaagent.service=log-visualization"

  # Ollama for Local LLM Inference
  ollama:
    image: ollama/ollama:latest
    container_name: llamaagent-ollama
    restart: unless-stopped
    environment:
      OLLAMA_HOST: "0.0.0.0"
      OLLAMA_ORIGINS: "*"
      OLLAMA_MODELS: ${OLLAMA_MODELS:-llama3.2:3b}
    volumes:
      - ollama_data:/root/.ollama
      - ./scripts/ollama-setup.sh:/usr/local/bin/ollama-setup.sh:ro
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    networks:
      - llamaagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        ollama serve &
        sleep 30
        for model in $${OLLAMA_MODELS//,/ }; do
          echo "Pulling model: $$model"
          ollama pull $$model || echo "Failed to pull $$model"
        done
        wait
    labels:
      - "com.llamaagent.service=local-llm"

  # Database Backup Service
  db-backup:
    image: postgres:16-alpine
    container_name: llamaagent-db-backup
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-llamaagent}
      POSTGRES_USER: ${POSTGRES_USER:-llamaagent}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secure_password}
      PGHOST: postgres
      BACKUP_SCHEDULE: ${BACKUP_SCHEDULE:-0 2 * * *}
    volumes:
      - postgres_backups:/backups
      - ./scripts/db-backup.sh:/usr/local/bin/db-backup.sh:ro
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - llamaagent-network
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "$$BACKUP_SCHEDULE /usr/local/bin/db-backup.sh" > /etc/crontabs/root
        crond -f
    labels:
      - "com.llamaagent.service=backup"

  # Health Check Service
  health-check:
    image: willfarrell/autoheal:latest
    container_name: llamaagent-autoheal
    restart: unless-stopped
    environment:
      AUTOHEAL_CONTAINER_LABEL: "autoheal=true"
      AUTOHEAL_INTERVAL: ${AUTOHEAL_INTERVAL:-5}
      AUTOHEAL_START_PERIOD: ${AUTOHEAL_START_PERIOD:-0}
      AUTOHEAL_DEFAULT_STOP_TIMEOUT: ${AUTOHEAL_STOP_TIMEOUT:-10}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    labels:
      - "com.llamaagent.service=health-check"

networks:
  llamaagent-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16
          gateway: 172.30.0.1
    driver_opts:
      com.docker.network.bridge.name: llamaagent-br
      com.docker.network.driver.mtu: 1500

volumes:
  # Application Data
  app_logs:
    name: llamaagent-app-logs
  app_data:
    name: llamaagent-app-data
  app_cache:
    name: llamaagent-app-cache
  app_uploads:
    name: llamaagent-app-uploads
  app_exports:
    name: llamaagent-app-exports
  app_backups:
    name: llamaagent-app-backups

  # Database Data
  postgres_data:
    name: llamaagent-postgres-data
  postgres_backups:
    name: llamaagent-postgres-backups
  redis_data:
    name: llamaagent-redis-data
  qdrant_data:
    name: llamaagent-qdrant-data

  # Monitoring Data
  prometheus_data:
    name: llamaagent-prometheus-data
  grafana_data:
    name: llamaagent-grafana-data
  jaeger_data:
    name: llamaagent-jaeger-data

  # Logging Data
  elasticsearch_data:
    name: llamaagent-elasticsearch-data

  # Web Services Data
  nginx_cache:
    name: llamaagent-nginx-cache
  nginx_logs:
    name: llamaagent-nginx-logs

  # AI Services Data
  ollama_data:
    name: llamaagent-ollama-data
