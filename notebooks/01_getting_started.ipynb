{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaAgent: Getting Started\n",
    "\n",
    "Welcome to LlamaAgent - a comprehensive AI agent framework with OpenAI Agents SDK integration!\n",
    "\n",
    "This notebook will guide you through:\n",
    "1. Basic agent creation and execution\n",
    "2. Using tools with agents\n",
    "3. Multi-agent orchestration\n",
    "4. OpenAI integration\n",
    "5. Advanced features (SPRE, budget tracking, etc.)\n",
    "\n",
    "**Author:** Nik Jois <nikjois@llamasearch.ai>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's ensure all dependencies are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LlamaAgent (if not already installed)\n",
    "!pip install -e ..\n",
    "\n",
    "# Import required modules\n",
    "import os\n",
    "\n",
    "# LlamaAgent imports\n",
    "from llamaagent import AgentConfig, AgentRole, ReactAgent\n",
    "from llamaagent.llm import create_provider\n",
    "from llamaagent.tools import ToolRegistry, get_all_tools\n",
    "\n",
    "print(\"✓ LlamaAgent imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Your First Agent\n",
    "\n",
    "Let's create a simple agent that can perform calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent configuration\n",
    "config = AgentConfig(\n",
    "    name=\"CalculatorAgent\",\n",
    "    role=AgentRole.SPECIALIST,\n",
    "    description=\"An agent that performs mathematical calculations\",\n",
    "    max_iterations=5,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Create the agent with mock provider (no API key needed)\n",
    "agent = ReactAgent(\n",
    "    config=config,\n",
    "    llm_provider=create_provider(\"mock\")\n",
    ")\n",
    "\n",
    "print(f\"✓ Created agent: {agent.name}\")\n",
    "print(f\"  Role: {config.role.value}\")\n",
    "print(f\"  Description: {config.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a simple task\n",
    "async def run_calculation():\n",
    "    task = \"Calculate the sum of squares from 1 to 10\"\n",
    "    response = await agent.execute(task)\n",
    "    \n",
    "    print(f\"Task: {task}\")\n",
    "    print(f\"Success: {response.success}\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "    print(f\"Execution time: {response.execution_time:.2f}s\")\n",
    "    \n",
    "await run_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding Tools to Agents\n",
    "\n",
    "Tools give agents the ability to perform specific actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool registry and add tools\n",
    "tools = ToolRegistry()\n",
    "\n",
    "# Get all available tools\n",
    "available_tools = get_all_tools()\n",
    "for tool in available_tools:\n",
    "    tools.register(tool)\n",
    "    print(f\"✓ Registered tool: {tool.name}\")\n",
    "\n",
    "# Create an agent with tools\n",
    "tool_agent_config = AgentConfig(\n",
    "    name=\"ToolAgent\",\n",
    "    role=AgentRole.EXECUTOR,\n",
    "    description=\"An agent that can use various tools\",\n",
    "    tools=[\"calculator\", \"python_repl\"]\n",
    ")\n",
    "\n",
    "tool_agent = ReactAgent(\n",
    "    config=tool_agent_config,\n",
    "    tools=tools,\n",
    "    llm_provider=create_provider(\"mock\")\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Created agent with {len(tools.list_tools())} tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a task that requires tools\n",
    "async def run_tool_task():\n",
    "    task = \"\"\"Write a Python function to calculate factorial and \n",
    "    then use it to find the factorial of 10\"\"\"\n",
    "    \n",
    "    response = await tool_agent.execute(task)\n",
    "    \n",
    "    print(f\"Task: {task}\")\n",
    "    print(f\"\\nSuccess: {response.success}\")\n",
    "    print(f\"\\nResponse: {response.content}\")\n",
    "    \n",
    "    # Show trace of tool usage\n",
    "    if response.trace:\n",
    "        tool_calls = [t for t in response.trace if t.get('type') == 'tool_execution_start']\n",
    "        print(f\"\\nTools used: {len(tool_calls)}\")\n",
    "        for call in tool_calls:\n",
    "            print(f\"  - {call.get('data', {}).get('tool_name', 'Unknown')}\")\n",
    "    \n",
    "await run_tool_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Agent Orchestration\n",
    "\n",
    "LlamaAgent supports coordinating multiple agents to solve complex tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamaagent.orchestrator import AgentOrchestrator, OrchestrationStrategy, WorkflowDefinition, WorkflowStep\n",
    "\n",
    "# Create orchestrator\n",
    "orchestrator = AgentOrchestrator()\n",
    "\n",
    "# Create specialized agents\n",
    "agents = {\n",
    "    \"researcher\": ReactAgent(\n",
    "        config=AgentConfig(\n",
    "            name=\"ResearchAgent\",\n",
    "            role=AgentRole.RESEARCHER,\n",
    "            description=\"Gathers information\"\n",
    "        ),\n",
    "        llm_provider=create_provider(\"mock\")\n",
    "    ),\n",
    "    \"analyst\": ReactAgent(\n",
    "        config=AgentConfig(\n",
    "            name=\"AnalystAgent\",\n",
    "            role=AgentRole.ANALYZER,\n",
    "            description=\"Analyzes data\"\n",
    "        ),\n",
    "        llm_provider=create_provider(\"mock\")\n",
    "    ),\n",
    "    \"writer\": ReactAgent(\n",
    "        config=AgentConfig(\n",
    "            name=\"WriterAgent\",\n",
    "            role=AgentRole.SPECIALIST,\n",
    "            description=\"Creates reports\"\n",
    "        ),\n",
    "        llm_provider=create_provider(\"mock\")\n",
    "    )\n",
    "}\n",
    "\n",
    "# Register agents\n",
    "for agent in agents.values():\n",
    "    orchestrator.register_agent(agent)\n",
    "    print(f\"✓ Registered {agent.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a workflow\n",
    "workflow = WorkflowDefinition(\n",
    "    workflow_id=\"report_workflow\",\n",
    "    name=\"Research Report Workflow\",\n",
    "    description=\"Create a research report on AI trends\",\n",
    "    strategy=OrchestrationStrategy.SEQUENTIAL,\n",
    "    steps=[\n",
    "        WorkflowStep(\n",
    "            step_id=\"research\",\n",
    "            agent_name=\"ResearchAgent\",\n",
    "            task=\"Research the latest trends in AI and machine learning\"\n",
    "        ),\n",
    "        WorkflowStep(\n",
    "            step_id=\"analyze\",\n",
    "            agent_name=\"AnalystAgent\",\n",
    "            task=\"Analyze the research findings and identify key patterns\",\n",
    "            dependencies=[\"research\"]\n",
    "        ),\n",
    "        WorkflowStep(\n",
    "            step_id=\"write\",\n",
    "            agent_name=\"WriterAgent\",\n",
    "            task=\"Write a concise report summarizing the findings\",\n",
    "            dependencies=[\"research\", \"analyze\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Register and execute workflow\n",
    "orchestrator.register_workflow(workflow)\n",
    "\n",
    "async def run_workflow():\n",
    "    print(f\"Executing workflow: {workflow.name}\\n\")\n",
    "    \n",
    "    result = await orchestrator.execute_workflow(workflow.workflow_id)\n",
    "    \n",
    "    print(\"\\nWorkflow completed!\")\n",
    "    print(f\"Success: {result.success}\")\n",
    "    print(f\"Total time: {result.execution_time:.2f}s\")\n",
    "    \n",
    "    # Show results from each step\n",
    "    for step_id, step_result in result.results.items():\n",
    "        print(f\"\\n{step_id}: {step_result.status.value}\")\n",
    "        if step_result.result and step_result.result.data:\n",
    "            print(f\"  Output preview: {str(step_result.result.data)[:100]}...\")\n",
    "\n",
    "await run_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. OpenAI Integration\n",
    "\n",
    "Now let's explore the OpenAI Agents SDK integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if OpenAI API key is available\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"✓ OpenAI API key found\")\n",
    "    use_openai = True\n",
    "else:\n",
    "    print(\"✗ No OpenAI API key found - using mock provider\")\n",
    "    print(\"  Set OPENAI_API_KEY environment variable to use OpenAI\")\n",
    "    use_openai = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamaagent.integration.openai_agents import create_openai_integration\n",
    "\n",
    "if use_openai:\n",
    "    # Create OpenAI integration\n",
    "    openai_integration = create_openai_integration(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        budget_limit=1.0  # $1 budget for demo\n",
    "    )\n",
    "    \n",
    "    # Create an agent with OpenAI\n",
    "    openai_agent = ReactAgent(\n",
    "        config=AgentConfig(\n",
    "            name=\"OpenAIAgent\",\n",
    "            role=AgentRole.GENERALIST,\n",
    "            description=\"Powered by OpenAI GPT-4\"\n",
    "        ),\n",
    "        llm_provider=create_provider(\"openai\", model_name=\"gpt-4o-mini\")\n",
    "    )\n",
    "    \n",
    "    # Register with integration\n",
    "    adapter = openai_integration.register_agent(openai_agent)\n",
    "    \n",
    "    print(\"✓ OpenAI integration configured\")\n",
    "    print(\"  Model: gpt-4o-mini\")\n",
    "    print(\"  Budget: $1.00\")\n",
    "else:\n",
    "    print(\"Skipping OpenAI integration (no API key)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a task with OpenAI (if available)\n",
    "if use_openai and 'openai_integration' in locals():\n",
    "    from llamaagent.types import TaskInput\n",
    "    \n",
    "    async def run_openai_task():\n",
    "        task = TaskInput(\n",
    "            id=\"openai_demo_001\",\n",
    "            task=\"Explain quantum computing in simple terms\",\n",
    "            agent_name=\"OpenAIAgent\"\n",
    "        )\n",
    "        \n",
    "        result = await openai_integration.run_task(\"OpenAIAgent\", task)\n",
    "        \n",
    "        print(f\"Task: {task.task}\")\n",
    "        print(f\"\\nSuccess: {result.success}\")\n",
    "        if result.result and result.result.data:\n",
    "            print(f\"\\nResponse: {result.result.data.get('response', 'No response')}\")\n",
    "        \n",
    "        # Show budget usage\n",
    "        budget = openai_integration.get_budget_status()\n",
    "        print(f\"\\nBudget used: ${budget['current_cost']:.4f}\")\n",
    "        print(f\"Remaining: ${budget['remaining_budget']:.4f}\")\n",
    "    \n",
    "    await run_openai_task()\n",
    "else:\n",
    "    print(\"OpenAI integration not available - using mock response\")\n",
    "    print(\"\\nMock Response: Quantum computing uses quantum bits (qubits) that can be \")\n",
    "    print(\"in multiple states simultaneously, unlike classical bits that are only 0 or 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Features: SPRE (Strategic Planning & Resourceful Execution)\n",
    "\n",
    "SPRE is LlamaAgent's advanced planning methodology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SPRE-enabled agent\n",
    "spre_config = AgentConfig(\n",
    "    name=\"SPREAgent\",\n",
    "    role=AgentRole.PLANNER,\n",
    "    description=\"Agent with Strategic Planning & Resourceful Execution\",\n",
    "    spree_enabled=True,  # Enable SPRE\n",
    "    tools=[\"calculator\", \"python_repl\"]\n",
    ")\n",
    "\n",
    "spre_agent = ReactAgent(\n",
    "    config=spre_config,\n",
    "    tools=tools,\n",
    "    llm_provider=create_provider(\"mock\")\n",
    ")\n",
    "\n",
    "print(\"✓ Created SPRE-enabled agent\")\n",
    "print(f\"  SPRE enabled: {spre_config.spree_enabled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a complex task with SPRE\n",
    "async def run_spre_task():\n",
    "    complex_task = \"\"\"Calculate the compound interest on $5000 at 8% for 5 years,\n",
    "    then determine how much you need to invest at the same rate to have $10000 after 5 years.\"\"\"\n",
    "    \n",
    "    print(f\"Task: {complex_task}\\n\")\n",
    "    \n",
    "    response = await spre_agent.execute(complex_task)\n",
    "    \n",
    "    print(f\"Success: {response.success}\")\n",
    "    print(f\"\\nResponse: {response.content}\")\n",
    "    \n",
    "    # Show planning events\n",
    "    if response.trace:\n",
    "        planning_events = [e for e in response.trace if e.get('type') == 'plan_generated']\n",
    "        if planning_events:\n",
    "            print(f\"\\nSPRE Planning detected: {len(planning_events)} plan(s) generated\")\n",
    "\n",
    "await run_spre_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitoring and Debugging\n",
    "\n",
    "LlamaAgent provides comprehensive monitoring capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with detailed tracing\n",
    "debug_config = AgentConfig(\n",
    "    name=\"DebugAgent\",\n",
    "    role=AgentRole.SPECIALIST,\n",
    "    description=\"Agent with detailed debugging\",\n",
    "    debug=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "debug_agent = ReactAgent(\n",
    "    config=debug_config,\n",
    "    llm_provider=create_provider(\"mock\")\n",
    ")\n",
    "\n",
    "# Execute and analyze trace\n",
    "async def debug_execution():\n",
    "    response = await debug_agent.execute(\"What is 2 + 2?\")\n",
    "    \n",
    "    print(f\"Response: {response.content}\")\n",
    "    \n",
    "    # Get execution trace\n",
    "    trace = debug_agent.get_trace()\n",
    "    if trace:\n",
    "        print(\"\\nExecution Trace:\")\n",
    "        print(f\"  Agent: {trace.agent_name}\")\n",
    "        print(f\"  Task: {trace.task}\")\n",
    "        print(f\"  Execution time: {trace.execution_time:.3f}s\")\n",
    "        print(f\"  Success: {trace.success}\")\n",
    "        print(f\"  Steps: {len(trace.steps)}\")\n",
    "        \n",
    "        for i, step in enumerate(trace.steps):\n",
    "            print(f\"\\n  Step {i+1}: {step['step_type']}\")\n",
    "            print(f\"    {step['description']}\")\n",
    "\n",
    "await debug_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Best Practices and Tips\n",
    "\n",
    "Here are some best practices for using LlamaAgent effectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Practice 1: Use appropriate agent roles\n",
    "print(\"Available Agent Roles:\")\n",
    "for role in AgentRole:\n",
    "    print(f\"  - {role.value}: {role.name}\")\n",
    "\n",
    "print(\"\\nTip: Choose roles that match the agent's primary function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Practice 2: Configure agents appropriately\n",
    "optimal_config = AgentConfig(\n",
    "    name=\"OptimalAgent\",\n",
    "    role=AgentRole.SPECIALIST,\n",
    "    description=\"Well-configured agent\",\n",
    "    max_iterations=10,      # Prevent infinite loops\n",
    "    temperature=0.1,        # Low temperature for consistency\n",
    "    timeout=60.0,          # Reasonable timeout\n",
    "    retry_attempts=3,       # Handle transient failures\n",
    "    memory_enabled=True,    # Enable conversation memory\n",
    "    streaming=False,        # Disable for batch processing\n",
    ")\n",
    "\n",
    "print(\"Optimal Configuration:\")\n",
    "for key, value in optimal_config.__dict__.items():\n",
    "    if not key.startswith('_'):\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Practice 3: Handle errors gracefully\n",
    "async def error_handling_example():\n",
    "    agent = ReactAgent(\n",
    "        config=AgentConfig(name=\"ErrorAgent\"),\n",
    "        llm_provider=create_provider(\"mock\")\n",
    "    )\n",
    "    \n",
    "    # Test with an edge case\n",
    "    try:\n",
    "        response = await agent.execute(\"\")\n",
    "        if response.success:\n",
    "            print(\"Empty task handled successfully\")\n",
    "        else:\n",
    "            print(f\"Task failed gracefully: {response.error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception caught: {type(e).__name__}: {e}\")\n",
    "\n",
    "await error_handling_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "You've now learned the basics of LlamaAgent! Here's what we covered:\n",
    "\n",
    "1. ✅ Creating and configuring agents\n",
    "2. ✅ Using tools with agents\n",
    "3. ✅ Multi-agent orchestration\n",
    "4. ✅ OpenAI integration\n",
    "5. ✅ SPRE methodology\n",
    "6. ✅ Monitoring and debugging\n",
    "7. ✅ Best practices\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore more examples in the `/examples` directory\n",
    "- Read the full documentation\n",
    "- Try building your own multi-agent system\n",
    "- Contribute to the project on GitHub\n",
    "\n",
    "Happy agent building! 🦙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "print(\"Notebook completed successfully!\")\n",
    "print(\"\\nFor questions or support:\")\n",
    "print(\"  Email: nikjois@llamasearch.ai\")\n",
    "print(\"  GitHub: https://github.com/nikjois/llamaagent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}